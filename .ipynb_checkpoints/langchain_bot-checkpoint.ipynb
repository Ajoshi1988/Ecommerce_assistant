{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "bcb0d081-2835-467b-8e5b-93c111ca55c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os, ollama, time, json, numpy as np\n",
    "import warnings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Literal, Dict, List\n",
    "\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from datetime import datetime\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "\n",
    "from numpy.linalg import norm\n",
    "import openai, re\n",
    "from pymongo import MongoClient\n",
    "import uuid\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY']='api-key'\n",
    "os.environ['LANGCHAIN_API_KEY']=\"lang-key\"\n",
    "\n",
    "\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Misscelanoues functions\n",
    "\n",
    "\n",
    "#Function to store the conversation data\n",
    "def store_conversation_data( random_uuid, input_query, tool_called ):\n",
    "    \n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"conversations_db\"]\n",
    "    collection = db[\"user_data\"]\n",
    "    \n",
    "\n",
    "    existing_user = collection.find_one({\"user_id\": random_uuid})\n",
    "\n",
    "    if existing_user:\n",
    "        # If the user exists, update the document by appending new data\n",
    "        collection.update_one(\n",
    "            {\"user_id\": random_uuid},\n",
    "            {\n",
    "                \"$addToSet\": {\n",
    "                    \"tool_called\": {\"$each\": tool_called},\n",
    "                    \"input_query\": {\"$each\": input_query}\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # If the user doesn't exist, create a new user\n",
    "        collection.insert_one({\n",
    "            \"user_id\": random_uuid,\n",
    "            \"tool_called\": tool_called,\n",
    "            \"input_query\": input_query\n",
    "        })\n",
    "\n",
    "    print(f\"Data has been successfully added/updated for user: {random_uuid}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def total_assembly(in_dict: Dict[str, str])->str:\n",
    "\n",
    "    in_dict_keys=list(in_dict.keys())\n",
    "    in_dict_values=list(in_dict.values())\n",
    "    out_html_list=[\"\"\"<div class=\"container text-center mt-4\"> \"\"\",\n",
    "               \"\"\"<p class=\"fw-bold fs-5 text-primary\">Following are the selected components</p>\"\"\",\n",
    "               \"\"\"<ol class=\"list-group list-group-numbered mx-auto mt-1\" style=\"max-width: 450px;\">\"\"\",\n",
    "     \n",
    "               ]\n",
    "    val_list=[]\n",
    "    for ky, val in zip(in_dict_keys, in_dict_values):\n",
    "\n",
    "        out_html_list.append( f\"\"\" <li class=\"list-group-item d-flex  align-items-center\"> {ky.upper()}: {val.split('@')[0].strip()}  </li>\"\"\"  )\n",
    "        val_list.append(int(val.split(\"@\")[1].replace(\"$\",'').strip()))\n",
    "\n",
    "    tail_html_list=[\n",
    "        \"</ol>\",\n",
    "        f\"\"\"<p class=\"fw-bold fs-5 text-primary\">Grand Total ${sum(val_list)}</p>\"\"\",\n",
    "        \n",
    "        \"</div>\"\n",
    "              \n",
    "       ]\n",
    "\n",
    "    final_html_list=out_html_list+tail_html_list\n",
    "    final_html_str=\"\".join(final_html_list)\n",
    "    \n",
    "    return(final_html_str)\n",
    "\n",
    "\n",
    "\n",
    "#Code Block for RAG Function\n",
    "def parse_file(filename):\n",
    "    with open(filename, encoding=\"utf-8-sig\") as f:\n",
    "        paragraphs = []\n",
    "        buffer = []\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                buffer.append(line)\n",
    "            elif len(buffer):\n",
    "                paragraphs.append((\" \").join(buffer))\n",
    "                buffer = []\n",
    "        if len(buffer):\n",
    "            paragraphs.append((\" \").join(buffer))\n",
    "        return paragraphs\n",
    "\n",
    "def save_embeddings(filename, embeddings):\n",
    "    # create dir if it doesn't exist\n",
    "    if not os.path.exists(\"embeddings\"):\n",
    "        os.makedirs(\"embeddings\")\n",
    "    # dump embeddings to json\n",
    "    with open(f\"embeddings/{filename}.json\", \"w\") as f:\n",
    "        json.dump(embeddings, f)\n",
    "\n",
    "\n",
    "def load_embeddings(filename):\n",
    "    # check if file exists\n",
    "    if not os.path.exists(f\"embeddings/{filename}.json\"):\n",
    "        return False\n",
    "    # load embeddings from json\n",
    "    with open(f\"embeddings/{filename}.json\", \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def get_embeddings(filename, modelname, chunks):\n",
    "    # check if embeddings are already saved\n",
    "    if (embeddings := load_embeddings(filename)) is not False:\n",
    "        return embeddings\n",
    "    # get embeddings from ollama\n",
    "    embeddings = [\n",
    "        ollama.embeddings(model=modelname, prompt=chunk)[\"embedding\"]\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "    # save embeddings\n",
    "    save_embeddings(filename, embeddings)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def find_most_similar(needle, haystack):\n",
    "    needle_norm = norm(needle)\n",
    "\n",
    "    similarity_scores = [\n",
    "        np.dot(needle, item) / (needle_norm * norm(item)) for item in haystack\n",
    "    ]\n",
    "\n",
    "    # print(needle, haystack[0])\n",
    "    # print(np.dot(needle, haystack[0]))\n",
    "    return sorted(zip(similarity_scores, range(len(haystack))), reverse=True)\n",
    "\n",
    "\n",
    "def rag_function(prompt, embedding_model=\"mxbai-embed-large:latest\", filename='laptop_data.txt'):\n",
    "\n",
    "    SYSTEM_PROMPT = \"\"\"You are a helpful reading assistant who answers questions\n",
    "        based on snippets of text provided in context. Answer only using the context provided,\n",
    "        being as concise as possible. If you're unsure, just say that you don't know.\n",
    "        Do not give answers that are outside the context given.\n",
    "        Answer in about 150 words for each prompt. Transform the input text in your own way to provide concise answers.\n",
    "        Context:\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    \n",
    "    paragraphs = parse_file(filename)\n",
    "\n",
    "    embeddings = get_embeddings(filename, embedding_model, paragraphs)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    prompt_embedding = ollama.embeddings(model=embedding_model, prompt=prompt)[\"embedding\"]\n",
    "    most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]\n",
    "\n",
    "    openai.api_key='api-key'\n",
    "\n",
    "    chat_completion = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\", temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":SYSTEM_PROMPT + \"\\n\".join(paragraphs[item[1]] for item in most_similar_chunks)  },\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "\n",
    "        )\n",
    "\n",
    "   \n",
    "\n",
    "    # print(\"\\n\\n\")\n",
    "    # print(chat_completion.choices[0].message.content)\n",
    "    return(chat_completion.choices[0].message.content)\n",
    "\n",
    "\n",
    "#Ingest all the data\n",
    "df_laptops=pd.read_excel('laptops.xlsx', dtype={'PRICE': int, 'RAM(GB)': int, 'STORAGE(GB)': int, 'RATINGS': float})\n",
    "df_laptops=df_laptops[['id', 'PRODUCT', 'BRAND', 'PRICE', 'RAM(GB)', 'STORAGE(GB)','PROCESSOR', 'RATINGS']]\n",
    "# df_CPU=pd.read_excel('CPU.xlsx')\n",
    "# df_GPU=pd.read_excel('GPU.xlsx')\n",
    "# df_monitor=pd.read_excel('monitor.xlsx')\n",
    "\n",
    "\n",
    "#List of all the prompts\n",
    "\n",
    "greet_prompt=PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"\"\"                  \n",
    "                  Your a very helpful assistant for a Ecommerce store, that sells computer and related accessories online.\n",
    "                  If the user greets, greet back. Your name is Maya.\n",
    "                  If the user expresses gratitude, give an appropriate response.\n",
    "                  If your name is asked, answer your name politely. If the user provides his/her name, use the name in your replies.\n",
    "                  Query: {query}\n",
    "                  \n",
    "                  \"\"\"\n",
    "       )\n",
    "\n",
    "\n",
    "\n",
    "def format_string(in_str:str)->str:\n",
    "   \n",
    "    in_str_split=re.split(r'(?=\\n\\d+\\.\\s)', in_str)\n",
    "    card_pattern=r'^\\d+\\..*'\n",
    "    format_list=[\"\"\"<div class= \"card-body\">\"\"\"]\n",
    "\n",
    "    for ele in in_str_split:\n",
    "        ele=ele.replace(\"\\n\", '')\n",
    "    \n",
    "        if re.search(card_pattern, ele):\n",
    "            ele= f\"\"\"<div class= \"card-content\"> {ele}  </div>\"\"\"\n",
    "        else:\n",
    "            ele= f\"\"\"<div class= \"card-title\"> {ele}  </div>\"\"\"\n",
    "            \n",
    "        format_list.append(ele)\n",
    "        \n",
    "    format_list.append(\"</div>\")\n",
    "    format_str= \"\".join(format_list)\n",
    "          \n",
    "          \n",
    "    return(format_str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def bot_greet(user_input:str)-> str:\n",
    "    \"\"\"Tool to be called when user greets, expresses gratitude, asks your name\"\"\"\n",
    "\n",
    "    # print(\"greet called\")\n",
    "    greet_llm_chain= greet_prompt | llm\n",
    "\n",
    "    response=greet_llm_chain.invoke(user_input)\n",
    "    \n",
    "    \n",
    "\n",
    "    try:\n",
    "        out_dict ={\n",
    "                  'response':response.content,\n",
    "                  'html':'no'\n",
    "            \n",
    "                  }\n",
    "        return(out_dict)\n",
    "    \n",
    "    except:\n",
    "        out_dict ={\n",
    "                  'response':'I am your Ecommerce Assistant, How may I assist you today?',\n",
    "                  'html':'no'\n",
    "            \n",
    "                  }\n",
    "\n",
    "        \n",
    "        return(out_dict)\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def bot_laptop(user_input:str):\n",
    "    \"\"\"Function to be called, when user inquires about computers, laptops, prices, ratings, brands\"\"\"\n",
    "    agent = create_pandas_dataframe_agent(\n",
    "            ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\"),\n",
    "            df_laptops,\n",
    "            verbose=True,\n",
    "            agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "            allow_dangerous_code=True\n",
    "        )\n",
    "\n",
    "    agent_str=agent.invoke(user_input)['output']\n",
    "    formatted_str=format_string(agent_str)\n",
    "    \n",
    "    out_dict ={\n",
    "                  'response':formatted_str,\n",
    "                  'html':'yes'\n",
    "            \n",
    "                  }\n",
    "   \n",
    "    \n",
    "\n",
    "    return(out_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def bot_general_info(user_input:str):\n",
    "    \"\"\"Function to be called, when user inquires about the store, reviews of different brands, product types and services provided, GPUS and their comparisons,\n",
    "     Payment options, Return Policy\"\"\"\n",
    "\n",
    "    response=rag_function(user_input)\n",
    "    \n",
    "    out_dict ={\n",
    "                  'response':response,\n",
    "                  'html':'yes'\n",
    "            \n",
    "                  }\n",
    " \n",
    "\n",
    "    return(out_dict)\n",
    "\n",
    "\n",
    "@tool\n",
    "def bot_assembly(user_input:str):\n",
    "    \"\"\"Function to be called, when user wants/requests to guide him in assembling or gathering individual components of computer/laptop\"\"\"\n",
    "\n",
    " \n",
    "    out_dict ={\n",
    "                  'response':'Alright, Lets start with processors, pick one',\n",
    "                   'html':'assemble_chain'\n",
    "            \n",
    "                  }\n",
    "    \n",
    "\n",
    "    return(out_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def call_tools(msg: AIMessage) -> Runnable:\n",
    "    \"\"\"Simple sequential tool calling helper.\"\"\"\n",
    "    tool_map = {tool.name: tool for tool in ecom_tools}\n",
    "   \n",
    "    tool_calls = msg.tool_calls.copy()\n",
    "\n",
    "    \n",
    "    #Introducing the Fall back statement\n",
    "    if len(tool_calls)==0:\n",
    "        print(\"========================Fallback Action=====================  \\n\")\n",
    "        print(\"I am the Food Assistant Alexa, I am here to assist you in ordering your delicious meal!\")\n",
    "    else:\n",
    "        for tool_call in tool_calls:\n",
    "\n",
    "           tool_call[\"output\"] = tool_map[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "           \n",
    "           if tool_call['name']:\n",
    "               tool_called=[tool_call['name']]\n",
    "           else:\n",
    "               tool_called=['None']\n",
    "               \n",
    "           print(tool_called)\n",
    "           return(tool_call[\"output\"]) \n",
    "       \n",
    "       \n",
    "       \n",
    "ecom_tools = [bot_greet, bot_laptop, bot_general_info, bot_assembly]\n",
    "llm_with_tools =  llm.bind_tools(ecom_tools) \n",
    "chain = llm_with_tools | call_tools\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b31f9d5e-72bd-444b-8398-d749be897c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bot_greet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'Hello! How can I assist you today?', 'html': 'no'}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"Hello I am Aditya, Who are you?\"\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f39e5a79-280d-442d-bb02-3bb0e33aa624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'Karnavati Computers is located in Ahmedabad, specifically in Vastrapur, Gujarat.',\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\" Does your shop has a physical location?\"\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "bf4bce37-13bf-4638-b646-37fade044cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bot_general_info']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'The e-commerce store provides several convenient payment options. Customers can pay using major credit and debit cards, including Visa, MasterCard, and American Express. Digital wallets like PayPal, Google Pay, and Apple Pay are also accepted. There are UPI payment methods available, such as PhonePe, Paytm, and Google Pay. The store also accepts Cash on Delivery (COD) for in-person payment, and offers Buy Now, Pay Later (BNPL) services through Klarna and Afterpay. Additional options include bank transfers, net banking, and gift cards.',\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"  What payment options do you entertain?\"\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "192e7929-4a63-42c7-af0b-35eebcb6b36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'Product types include laptops, laptop accessories (such as bags, cooling pads), monitors, headsets, webcams, keyboards, mice, and networking equipment. Services offered are expert consultation, free software installation, secure online payment, doorstep delivery, easy returns, warranty assistance, post-purchase technical support, customized business solutions, extended warranties, repair services, and exclusive discounts for students and professionals.',\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"  What are the product types and services do you provide?\"\n",
    "\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cd6aefb9-0073-4e68-be12-37187f6eeb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'For high-end gaming performance with cutting-edge features like ray tracing and DLSS, NVIDIA GPUs are recommended for their superior capabilities and support.',\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"  I am a gamer, which GPU would you suggest?\"\n",
    "\n",
    "\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8cbaad72-30bf-4589-a271-997a40f1904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': \"I don't have information on recent election winners in India.\",\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"Who won the election recently in India?\"\n",
    "\n",
    "\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "64192fdb-1f84-4b99-8fa9-436aec190b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find the best rated Dell laptops, you can filter the dataframe `df` for rows where the `BRAND` is 'DELL' and then sort the filtered dataframe by the `RATINGS` column in descending order. Here is the code to achieve this:\n",
      "\n",
      "```python\n",
      "best_rated_dell_laptops = df[df['BRAND'] == 'DELL'].sort_values(by='RATINGS', ascending=False)\n",
      "print(best_rated_dell_laptops)\n",
      "``` \n",
      "\n",
      "This code will filter the dataframe for Dell laptops and then sort them based on ratings in descending order, showing the best rated Dell laptops at the top.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': '<div class= \"card-body\"><div class= \"card-title\"> To find the best rated Dell laptops, you can filter the dataframe `df` for rows where the `BRAND` is \\'DELL\\' and then sort the filtered dataframe by the `RATINGS` column in descending order. Here is the code to achieve this:```pythonbest_rated_dell_laptops = df[df[\\'BRAND\\'] == \\'DELL\\'].sort_values(by=\\'RATINGS\\', ascending=False)print(best_rated_dell_laptops)``` This code will filter the dataframe for Dell laptops and then sort them based on ratings in descending order, showing the best rated Dell laptops at the top.  </div></div>',\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"Suggest me the best rated Dell laptops\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fc897e94-4379-4235-98d1-50051ebcbb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[df['PRICE'] < 25000]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m   id              PRODUCT   BRAND  PRICE  RAM(GB)  STORAGE(GB)  \\\n",
      "2   3      Lenovo Thinkpad  LENOVO  21499       16          100   \n",
      "3   4     HP Elitebook 820      HP  13999        8          256   \n",
      "4   5  Lenovo IdeaPad Slim  LENOVO  23990        8          512   \n",
      "6   7  Lenovo V15 Portable  LENOVO  23890        8          256   \n",
      "8   9     HP Elitebook 745      HP  20899        8          256   \n",
      "\n",
      "                  PROCESSOR  RATINGS  \n",
      "2          Intel i7 7th Gen      4.3  \n",
      "3   AMD Athlon silver 3050U      3.9  \n",
      "4  Intel core Celeron N4020      3.1  \n",
      "6      Intel Dual Processor      4.0  \n",
      "8     AMD Ryzen 5 Pro 2500U      5.0  \u001b[0m\u001b[32;1m\u001b[1;3mHere are some laptops under 25000:\n",
      "\n",
      "1. **Lenovo Thinkpad**\n",
      "   - Brand: LENOVO\n",
      "   - Price: 21499\n",
      "   - RAM: 16GB\n",
      "   - Storage: 100GB\n",
      "   - Processor: Intel i7 7th Gen\n",
      "   - Ratings: 4.3\n",
      "\n",
      "2. **HP Elitebook 820**\n",
      "   - Brand: HP\n",
      "   - Price: 13999\n",
      "   - RAM: 8GB\n",
      "   - Storage: 256GB\n",
      "   - Processor: AMD Athlon silver 3050U\n",
      "   - Ratings: 3.9\n",
      "\n",
      "3. **Lenovo IdeaPad Slim**\n",
      "   - Brand: LENOVO\n",
      "   - Price: 23990\n",
      "   - RAM: 8GB\n",
      "   - Storage: 512GB\n",
      "   - Processor: Intel core Celeron N4020\n",
      "   - Ratings: 3.1\n",
      "\n",
      "4. **Lenovo V15 Portable**\n",
      "   - Brand: LENOVO\n",
      "   - Price: 23890\n",
      "   - RAM: 8GB\n",
      "   - Storage: 256GB\n",
      "   - Processor: Intel Dual Processor\n",
      "   - Ratings: 4.0\n",
      "\n",
      "5. **HP Elitebook 745**\n",
      "   - Brand: HP\n",
      "   - Price: 20899\n",
      "   - RAM: 8GB\n",
      "   - Storage: 256GB\n",
      "   - Processor: AMD Ryzen 5 Pro 2500U\n",
      "   - Ratings: 5.0\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': '<div class= \"card-body\"><div class= \"card-title\"> Here are some laptops under 25000:  </div><div class= \"card-content\"> 1. **Lenovo Thinkpad**   - Brand: LENOVO   - Price: 21499   - RAM: 16GB   - Storage: 100GB   - Processor: Intel i7 7th Gen   - Ratings: 4.3  </div><div class= \"card-content\"> 2. **HP Elitebook 820**   - Brand: HP   - Price: 13999   - RAM: 8GB   - Storage: 256GB   - Processor: AMD Athlon silver 3050U   - Ratings: 3.9  </div><div class= \"card-content\"> 3. **Lenovo IdeaPad Slim**   - Brand: LENOVO   - Price: 23990   - RAM: 8GB   - Storage: 512GB   - Processor: Intel core Celeron N4020   - Ratings: 3.1  </div><div class= \"card-content\"> 4. **Lenovo V15 Portable**   - Brand: LENOVO   - Price: 23890   - RAM: 8GB   - Storage: 256GB   - Processor: Intel Dual Processor   - Ratings: 4.0  </div><div class= \"card-content\"> 5. **HP Elitebook 745**   - Brand: HP   - Price: 20899   - RAM: 8GB   - Storage: 256GB   - Processor: AMD Ryzen 5 Pro 2500U   - Ratings: 5.0  </div></div>',\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"The laptops with prices under 25000.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1604c1-8bd5-47d4-8350-2ba268b42220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "90de0943-c6cd-4c05-a6fa-7bc2632e4773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `python_repl_ast` with `{'query': \"df[(df['RAM(GB)'] >= 8) & (df['STORAGE(GB)'] > 256)]\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m   id              PRODUCT   BRAND  PRICE  RAM(GB)  STORAGE(GB)  \\\n",
      "0   1              Dell 15    DELL  45000        8          512   \n",
      "1   2   Dell Inspiron 3530    DELL  55155       16          512   \n",
      "4   5  Lenovo IdeaPad Slim  LENOVO  23990        8          512   \n",
      "5   6        Lenovo V15 G4  LENOVO  27088        8          512   \n",
      "7   8               HP 15S      HP  35490        8          512   \n",
      "9  10  Dell Latittude 3540    DELL  35499       16          512   \n",
      "\n",
      "                      PROCESSOR  RATINGS  \n",
      "0                      i5-1235U      3.5  \n",
      "1                      i5-1334U      3.7  \n",
      "4      Intel core Celeron N4020      3.1  \n",
      "5    AMD Ryzen 3 7320U QuadCore      4.7  \n",
      "7              i3 core 12th Gen      4.1  \n",
      "9  Intel core i3 12th Gen 1215U      5.0  \u001b[0m\u001b[32;1m\u001b[1;3mThe laptops with 8GB RAM and above 256GB storage are:\n",
      "\n",
      "1. Dell 15 by DELL\n",
      "2. Dell Inspiron 3530 by DELL\n",
      "3. Lenovo IdeaPad Slim by LENOVO\n",
      "4. Lenovo V15 G4 by LENOVO\n",
      "5. HP 15S by HP\n",
      "6. Dell Latittude 3540 by DELL\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': '<div class= \"card-body\"><div class= \"card-title\"> The laptops with 8GB RAM and above 256GB storage are:  </div><div class= \"card-content\"> 1. Dell 15 by DELL  </div><div class= \"card-content\"> 2. Dell Inspiron 3530 by DELL  </div><div class= \"card-content\"> 3. Lenovo IdeaPad Slim by LENOVO  </div><div class= \"card-content\"> 4. Lenovo V15 G4 by LENOVO  </div><div class= \"card-content\"> 5. HP 15S by HP  </div><div class= \"card-content\"> 6. Dell Latittude 3540 by DELL  </div></div>',\n",
       " 'html': 'yes'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_query=\"Laptops with  8GB RAM and above 256GB storage.\"\n",
    "\n",
    "\n",
    "chain_response=chain.invoke(str(bot_query))\n",
    "chain_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd4876-7e51-4cfd-89f5-606f503e6ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69882c7-d5e8-4554-917e-4242ff1cef5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "8b0d13bb-42f8-49c7-9ab5-df2ddd0a3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"conversations_db\"]\n",
    "collection = db[\"user_data\"]\n",
    "random_user = \"1234\"  # Generate a random user ID\n",
    "tool_called = ['bot_call']\n",
    "input_query = ['White rabbit Elephant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "c1ad57d1-ec47-4311-827a-edc980d69891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully added/updated for user: 1234\n"
     ]
    }
   ],
   "source": [
    "def store_conversation_data(mongo_client, collection, random_uuid, db, input_query, tool_called ):\n",
    "\n",
    "    existing_user = collection.find_one({\"user_id\": random_user})\n",
    "\n",
    "    if existing_user:\n",
    "        # If the user exists, update the document by appending new data\n",
    "        collection.update_one(\n",
    "            {\"user_id\": random_user},\n",
    "            {\n",
    "                \"$addToSet\": {\n",
    "                    \"tool_called\": {\"$each\": tool_called},\n",
    "                    \"input_query\": {\"$each\": input_query}\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # If the user doesn't exist, create a new user\n",
    "        collection.insert_one({\n",
    "            \"user_id\": random_user,\n",
    "            \"tool_called\": tool_called,\n",
    "            \"input_query\": input_query\n",
    "        })\n",
    "\n",
    "    print(f\"Data has been successfully added/updated for user: {random_user}\")\n",
    "\n",
    "\n",
    "    \n",
    "store_conversation_data(client, collection, random_uuid, db, input_query, tool_called )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629d8698-b8a0-484f-876e-77840d530996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6eb3b5f3-3063-4362-ab04-682574e62bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7a674528-c8ce-406c-aebe-0b8a5b59bf40'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2841b83e-3d41-4e4b-bee5-7c3f099ee866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7a674528-c8ce-406c-aebe-0b8a5b59bf40'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a922cec0-0692-4f7c-ad5b-3f6d7a104a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully added/updated for user: 7a674528-c8ce-406c-aebe-0b8a5b59bf40\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import uuid\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"conversations_db\"]\n",
    "collection = db[\"user_data\"]\n",
    "\n",
    "# Data to be inserted or updated\n",
    "random_user = random_user  # Generate a random user ID\n",
    "tool_called = ['bot_greet']\n",
    "input_query = ['I am Aditya']\n",
    "\n",
    "# Check if the user already exists\n",
    "existing_user = collection.find_one({\"user_id\": random_user})\n",
    "\n",
    "if existing_user:\n",
    "    # If the user exists, update the document by appending new data\n",
    "    collection.update_one(\n",
    "        {\"user_id\": random_user},\n",
    "        {\n",
    "            \"$addToSet\": {\n",
    "                \"tool_called\": {\"$each\": tool_called},\n",
    "                \"input_query\": {\"$each\": input_query}\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    # If the user doesn't exist, create a new user\n",
    "    collection.insert_one({\n",
    "        \"user_id\": random_user,\n",
    "        \"tool_called\": tool_called,\n",
    "        \"input_query\": input_query\n",
    "    })\n",
    "\n",
    "print(f\"Data has been successfully added/updated for user: {random_user}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fee206-4751-49ea-802e-cc77e1627206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "1051c3a7-f67e-46f2-b7b8-7347ee8c3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_conversation_data( random_uuid, input_query, tool_called ):\n",
    "    \n",
    "    client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "    db = client[\"conversations_db\"]\n",
    "    collection = db[\"user_data\"]\n",
    "    \n",
    "\n",
    "    existing_user = collection.find_one({\"user_id\": random_uuid})\n",
    "\n",
    "    if existing_user:\n",
    "        # If the user exists, update the document by appending new data\n",
    "        collection.update_one(\n",
    "            {\"user_id\": random_uuid},\n",
    "            {\n",
    "                \"$addToSet\": {\n",
    "                    \"tool_called\": {\"$each\": tool_called},\n",
    "                    \"input_query\": {\"$each\": input_query}\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # If the user doesn't exist, create a new user\n",
    "        collection.insert_one({\n",
    "            \"user_id\": random_uuid,\n",
    "            \"tool_called\": tool_called,\n",
    "            \"input_query\": input_query\n",
    "        })\n",
    "\n",
    "    print(f\"Data has been successfully added/updated for user: {random_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0369a917-44d8-4402-84e4-07f7f85b0914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully added/updated for user: 1234\n"
     ]
    }
   ],
   "source": [
    "store_conversation_data( '1234', ['Jumba'], ['botter'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "9bf71a63-af28-4e16-8298-72dca6a61b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk={'CPU': 'Intel Core i9-13900K @ $700', 'GPU': 'AMD Radeon RX 7900 XTX @ $740', 'SSD': 'Crucial P5 Plus (1TB) @ $70', 'monitor': 'ASUS ROG Swift PG259QN (24.5-inch) @ $700', 'buyer_id': 'c5a8f1ef-9a98-44a9-b7fa-ea2e5ca33027'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9ff7ac3a-07ac-4341-b21b-807201c9e9c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[242], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Ecom\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\Desktop\\Ecom\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\Ecom\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\Desktop\\Ecom\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09bc8b-4b37-440b-9c0c-f17cc72b8c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
