{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44ca81b-98ac-4be4-8221-fc5dbcd541fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import warnings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from datetime import datetime\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4279ee64-5767-40d3-824a-f36158de236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def tool_greet(in_str:str):\n",
    "    \"\"\"Tool to be called when user greets\"\"\"\n",
    "    print(f\"{in_str}\")\n",
    "    return(\"Tool called\")\n",
    "\n",
    "@tool\n",
    "def tool_inquiry(in_str:str):\n",
    "    \"\"\"Tool to be called when user inquires about a specific product in the store\"\"\"\n",
    "    print(f\"Inquiry started{in_str}\")\n",
    "    return(\"Inquiry Started\")\n",
    "\n",
    "\n",
    "tools = [tool_greet, tool_inquiry]\n",
    "llm_with_tools =  llm.bind_tools(tools) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c495fb4e-9f27-4441-bd0f-b959d99a1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State):\n",
    "\n",
    "    # print(llm_with_tools.invoke(state[\"messages\"]))\n",
    "    print(\"White Rabbit\")\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "916366eb-78d3-4bb1-9bb8-d78df562a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool_greet, tool_inquiry])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b57777e7-44f8-462d-a4c1-d3c85f200cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White Rabbit\n",
      "Hi there! I am Aditya\n",
      "White Rabbit\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! I am Aditya\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.invoke(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ffabd3a1-734d-426e-9055-19684e9deadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Aditya! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 290, 'total_tokens': 303, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f04acbbd-4a78-4e51-a7f0-5da2b9ce7277-0', usage_metadata={'input_tokens': 290, 'output_tokens': 13, 'total_tokens': 303, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "13571153-9ca5-4f26-8764-601325796bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='Tool called', name='tool_greet', id='32d1c17d-edc9-49a8-ac34-23d40b85b477', tool_call_id='call_NJbPO1XjMhGv6hOEpngcgSkg')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events['messages'][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9a41477-1fb0-474b-9f8d-bf0925775609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inquiry startedHere\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Inquiry Started'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_inquiry.invoke(\"Here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea0e3975-f0b7-4366-9be6-70d116f9a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inquiry startedHere\n"
     ]
    }
   ],
   "source": [
    "kk=eval('tool_inquiry').invoke(\"Here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f069fb6-f58f-4b56-9ad2-3a42e4d8cc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inquiry Started'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6346b5-07fc-4b15-9e84-19b19e30122a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk={'name':'Aditya'}\n",
    "list(kk.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c789e3-7a2e-4b93-a2ae-c735e34abb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'name' in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "473715a9-7ba1-4137-8fa5-2b966e5770e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I will be attending a conference on Machine Learning in San Francisco next Monday.\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2451dc45-5b58-48ec-a566-cd4b24cc3d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate(\n",
    "\n",
    "         input_variables=[\"query\"],\n",
    "         template=\"\"\" Extract all the entities in the query and present them in python dictionary with keys and values.\n",
    "                      Use lower case letters only\n",
    "          \n",
    "\n",
    "          Query: {query}\n",
    "          \n",
    "          \"\"\"\n",
    "           )\n",
    "   \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.0)\n",
    "\n",
    "# llm_chain=prompt_template | llm\n",
    "# raw_response = llm_chain.invoke(query)['content']\n",
    "\n",
    "llm_chain= prompt_template | llm\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2178924-4391-4691-ad5a-dd3cf13694df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'new delhi', 'food': 'pani puri', 'item': 'nvidia graphics card'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_response = llm_chain.invoke(\"I am visiting New Delhi to eat Pani puri and purchase Nvidia Graphics Card\")\n",
    "raw_response\n",
    "eval(raw_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243aaacd-46b1-412d-b768-684e30bb1819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed682fcb-b0f4-48f7-bb06-f54b15de6c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf8a966-314e-4f31-a1c5-397bdcb44514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Aditya!\n",
      "Your age is 25.\n",
      "You are from India.\n",
      "No arguments provided.\n"
     ]
    }
   ],
   "source": [
    "def process_arguments(**kwargs):\n",
    "    \n",
    "    if \"name\" in list(kwargs.keys()):\n",
    "        print(f\"Hello, {kwargs['name']}!\")\n",
    "    \n",
    "    if \"age\" in kwargs:\n",
    "        print(f\"Your age is {kwargs['age']}.\")\n",
    "    \n",
    "    if \"location\" in kwargs:\n",
    "        print(f\"You are from {kwargs['location']}.\")\n",
    "    \n",
    "    if not kwargs:\n",
    "        print(\"No arguments provided.\")\n",
    "\n",
    "# Example usage:\n",
    "process_arguments(name=\"Aditya\", age=25)\n",
    "process_arguments(location=\"India\")\n",
    "process_arguments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fbe3876-245b-46d6-a5d4-1e3b7e641b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Aditya!\n",
      "Your age is 25.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m process_arguments(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAditya\u001b[39m\u001b[38;5;124m\"\u001b[39m, age\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m process_arguments(location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndia\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[43mnull\u001b[49m)\n\u001b[0;32m      4\u001b[0m process_arguments()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "process_arguments(name=\"Aditya\", age=25)\n",
    "process_arguments(location=\"India\", name=null)\n",
    "process_arguments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d20ec-426b-4fab-bdda-8ce3498d9963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
